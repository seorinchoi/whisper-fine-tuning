{
  "best_metric": 0.18710331618785858,
  "best_model_checkpoint": "./whisper-train-1029/checkpoint-12000",
  "epoch": 9.558522914606002,
  "eval_steps": 500,
  "global_step": 14500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03297065611605671,
      "grad_norm": 97.6441879272461,
      "learning_rate": 1e-07,
      "loss": 3.5186,
      "step": 50
    },
    {
      "epoch": 0.06594131223211341,
      "grad_norm": 53.89746856689453,
      "learning_rate": 2e-07,
      "loss": 3.2458,
      "step": 100
    },
    {
      "epoch": 0.09891196834817013,
      "grad_norm": 27.127574920654297,
      "learning_rate": 3e-07,
      "loss": 2.744,
      "step": 150
    },
    {
      "epoch": 0.13188262446422683,
      "grad_norm": 26.044164657592773,
      "learning_rate": 4e-07,
      "loss": 2.0659,
      "step": 200
    },
    {
      "epoch": 0.16485328058028353,
      "grad_norm": 19.379148483276367,
      "learning_rate": 5e-07,
      "loss": 1.1581,
      "step": 250
    },
    {
      "epoch": 0.19782393669634027,
      "grad_norm": 14.667716026306152,
      "learning_rate": 6e-07,
      "loss": 0.9332,
      "step": 300
    },
    {
      "epoch": 0.23079459281239698,
      "grad_norm": 13.936891555786133,
      "learning_rate": 7e-07,
      "loss": 0.8329,
      "step": 350
    },
    {
      "epoch": 0.26376524892845365,
      "grad_norm": 13.242010116577148,
      "learning_rate": 8e-07,
      "loss": 0.7983,
      "step": 400
    },
    {
      "epoch": 0.29673590504451036,
      "grad_norm": 15.84188175201416,
      "learning_rate": 9e-07,
      "loss": 0.7319,
      "step": 450
    },
    {
      "epoch": 0.32970656116056707,
      "grad_norm": 13.575983047485352,
      "learning_rate": 1e-06,
      "loss": 0.6693,
      "step": 500
    },
    {
      "epoch": 0.32970656116056707,
      "eval_loss": 0.642537534236908,
      "eval_runtime": 435.2276,
      "eval_samples_per_second": 13.935,
      "eval_steps_per_second": 1.744,
      "step": 500
    },
    {
      "epoch": 0.36267721727662383,
      "grad_norm": 13.263381958007812,
      "learning_rate": 9.974358974358974e-07,
      "loss": 0.6156,
      "step": 550
    },
    {
      "epoch": 0.39564787339268054,
      "grad_norm": 14.251731872558594,
      "learning_rate": 9.948717948717949e-07,
      "loss": 0.5724,
      "step": 600
    },
    {
      "epoch": 0.42861852950873724,
      "grad_norm": 13.410656929016113,
      "learning_rate": 9.923076923076923e-07,
      "loss": 0.5046,
      "step": 650
    },
    {
      "epoch": 0.46158918562479395,
      "grad_norm": 13.057379722595215,
      "learning_rate": 9.897435897435898e-07,
      "loss": 0.4218,
      "step": 700
    },
    {
      "epoch": 0.49455984174085066,
      "grad_norm": 8.749603271484375,
      "learning_rate": 9.871794871794872e-07,
      "loss": 0.3244,
      "step": 750
    },
    {
      "epoch": 0.5275304978569073,
      "grad_norm": 7.843911647796631,
      "learning_rate": 9.846153846153847e-07,
      "loss": 0.2858,
      "step": 800
    },
    {
      "epoch": 0.5605011539729641,
      "grad_norm": 7.698041915893555,
      "learning_rate": 9.820512820512819e-07,
      "loss": 0.2712,
      "step": 850
    },
    {
      "epoch": 0.5934718100890207,
      "grad_norm": 8.802988052368164,
      "learning_rate": 9.794871794871793e-07,
      "loss": 0.2586,
      "step": 900
    },
    {
      "epoch": 0.6264424662050775,
      "grad_norm": 7.527097225189209,
      "learning_rate": 9.769230769230768e-07,
      "loss": 0.2714,
      "step": 950
    },
    {
      "epoch": 0.6594131223211341,
      "grad_norm": 8.798140525817871,
      "learning_rate": 9.743589743589742e-07,
      "loss": 0.2829,
      "step": 1000
    },
    {
      "epoch": 0.6594131223211341,
      "eval_loss": 0.2650439143180847,
      "eval_runtime": 427.1642,
      "eval_samples_per_second": 14.198,
      "eval_steps_per_second": 1.777,
      "step": 1000
    },
    {
      "epoch": 0.6923837784371909,
      "grad_norm": 8.00542163848877,
      "learning_rate": 9.717948717948717e-07,
      "loss": 0.2758,
      "step": 1050
    },
    {
      "epoch": 0.7253544345532477,
      "grad_norm": 8.706518173217773,
      "learning_rate": 9.692307692307691e-07,
      "loss": 0.2931,
      "step": 1100
    },
    {
      "epoch": 0.7583250906693043,
      "grad_norm": 7.455926895141602,
      "learning_rate": 9.666666666666666e-07,
      "loss": 0.2556,
      "step": 1150
    },
    {
      "epoch": 0.7912957467853611,
      "grad_norm": 6.612678527832031,
      "learning_rate": 9.64102564102564e-07,
      "loss": 0.2667,
      "step": 1200
    },
    {
      "epoch": 0.8242664029014177,
      "grad_norm": 6.310594081878662,
      "learning_rate": 9.615384615384615e-07,
      "loss": 0.2561,
      "step": 1250
    },
    {
      "epoch": 0.8572370590174745,
      "grad_norm": 6.273046970367432,
      "learning_rate": 9.58974358974359e-07,
      "loss": 0.2556,
      "step": 1300
    },
    {
      "epoch": 0.8902077151335311,
      "grad_norm": 9.02376651763916,
      "learning_rate": 9.564102564102564e-07,
      "loss": 0.262,
      "step": 1350
    },
    {
      "epoch": 0.9231783712495879,
      "grad_norm": 8.899892807006836,
      "learning_rate": 9.538461538461538e-07,
      "loss": 0.2541,
      "step": 1400
    },
    {
      "epoch": 0.9561490273656446,
      "grad_norm": 8.593973159790039,
      "learning_rate": 9.512820512820512e-07,
      "loss": 0.2417,
      "step": 1450
    },
    {
      "epoch": 0.9891196834817013,
      "grad_norm": 7.152565002441406,
      "learning_rate": 9.487179487179486e-07,
      "loss": 0.2456,
      "step": 1500
    },
    {
      "epoch": 0.9891196834817013,
      "eval_loss": 0.2440265566110611,
      "eval_runtime": 428.3453,
      "eval_samples_per_second": 14.159,
      "eval_steps_per_second": 1.772,
      "step": 1500
    },
    {
      "epoch": 1.0217606330365974,
      "grad_norm": 8.159341812133789,
      "learning_rate": 9.461538461538461e-07,
      "loss": 0.2317,
      "step": 1550
    },
    {
      "epoch": 1.0547312891526541,
      "grad_norm": 7.813035011291504,
      "learning_rate": 9.435897435897435e-07,
      "loss": 0.216,
      "step": 1600
    },
    {
      "epoch": 1.087701945268711,
      "grad_norm": 5.946143627166748,
      "learning_rate": 9.41025641025641e-07,
      "loss": 0.2022,
      "step": 1650
    },
    {
      "epoch": 1.1206726013847677,
      "grad_norm": 6.507411479949951,
      "learning_rate": 9.384615384615384e-07,
      "loss": 0.2199,
      "step": 1700
    },
    {
      "epoch": 1.1536432575008242,
      "grad_norm": 7.662243843078613,
      "learning_rate": 9.358974358974359e-07,
      "loss": 0.212,
      "step": 1750
    },
    {
      "epoch": 1.186613913616881,
      "grad_norm": 7.884157180786133,
      "learning_rate": 9.333333333333333e-07,
      "loss": 0.2084,
      "step": 1800
    },
    {
      "epoch": 1.2195845697329377,
      "grad_norm": 7.875664710998535,
      "learning_rate": 9.307692307692308e-07,
      "loss": 0.2052,
      "step": 1850
    },
    {
      "epoch": 1.2525552258489943,
      "grad_norm": 6.840819835662842,
      "learning_rate": 9.282051282051282e-07,
      "loss": 0.2249,
      "step": 1900
    },
    {
      "epoch": 1.285525881965051,
      "grad_norm": 5.271485805511475,
      "learning_rate": 9.256410256410257e-07,
      "loss": 0.2158,
      "step": 1950
    },
    {
      "epoch": 1.3184965380811078,
      "grad_norm": 5.9642205238342285,
      "learning_rate": 9.230769230769231e-07,
      "loss": 0.2133,
      "step": 2000
    },
    {
      "epoch": 1.3184965380811078,
      "eval_loss": 0.23334254324436188,
      "eval_runtime": 426.7064,
      "eval_samples_per_second": 14.214,
      "eval_steps_per_second": 1.779,
      "step": 2000
    },
    {
      "epoch": 1.3514671941971645,
      "grad_norm": 7.524890422821045,
      "learning_rate": 9.205128205128205e-07,
      "loss": 0.2142,
      "step": 2050
    },
    {
      "epoch": 1.3844378503132213,
      "grad_norm": 6.728856563568115,
      "learning_rate": 9.179487179487179e-07,
      "loss": 0.2174,
      "step": 2100
    },
    {
      "epoch": 1.417408506429278,
      "grad_norm": 5.4828338623046875,
      "learning_rate": 9.153846153846153e-07,
      "loss": 0.1996,
      "step": 2150
    },
    {
      "epoch": 1.4503791625453346,
      "grad_norm": 6.386958122253418,
      "learning_rate": 9.128205128205127e-07,
      "loss": 0.1957,
      "step": 2200
    },
    {
      "epoch": 1.4833498186613914,
      "grad_norm": 6.284536838531494,
      "learning_rate": 9.102564102564102e-07,
      "loss": 0.2074,
      "step": 2250
    },
    {
      "epoch": 1.516320474777448,
      "grad_norm": 6.976438045501709,
      "learning_rate": 9.076923076923076e-07,
      "loss": 0.2143,
      "step": 2300
    },
    {
      "epoch": 1.5492911308935047,
      "grad_norm": 7.462982177734375,
      "learning_rate": 9.051282051282051e-07,
      "loss": 0.199,
      "step": 2350
    },
    {
      "epoch": 1.5822617870095614,
      "grad_norm": 8.140387535095215,
      "learning_rate": 9.025641025641025e-07,
      "loss": 0.2091,
      "step": 2400
    },
    {
      "epoch": 1.6152324431256182,
      "grad_norm": 6.707614421844482,
      "learning_rate": 9e-07,
      "loss": 0.2142,
      "step": 2450
    },
    {
      "epoch": 1.648203099241675,
      "grad_norm": 6.4112467765808105,
      "learning_rate": 8.974358974358974e-07,
      "loss": 0.1952,
      "step": 2500
    },
    {
      "epoch": 1.648203099241675,
      "eval_loss": 0.22438964247703552,
      "eval_runtime": 430.9412,
      "eval_samples_per_second": 14.074,
      "eval_steps_per_second": 1.761,
      "step": 2500
    },
    {
      "epoch": 1.6811737553577317,
      "grad_norm": 5.349277973175049,
      "learning_rate": 8.948717948717949e-07,
      "loss": 0.2103,
      "step": 2550
    },
    {
      "epoch": 1.7141444114737885,
      "grad_norm": 6.287600040435791,
      "learning_rate": 8.923076923076923e-07,
      "loss": 0.2109,
      "step": 2600
    },
    {
      "epoch": 1.747115067589845,
      "grad_norm": 7.442455768585205,
      "learning_rate": 8.897435897435897e-07,
      "loss": 0.2163,
      "step": 2650
    },
    {
      "epoch": 1.7800857237059018,
      "grad_norm": 6.020671844482422,
      "learning_rate": 8.871794871794871e-07,
      "loss": 0.2018,
      "step": 2700
    },
    {
      "epoch": 1.8130563798219583,
      "grad_norm": 7.218172073364258,
      "learning_rate": 8.846153846153846e-07,
      "loss": 0.2017,
      "step": 2750
    },
    {
      "epoch": 1.846027035938015,
      "grad_norm": 7.797781944274902,
      "learning_rate": 8.82051282051282e-07,
      "loss": 0.2034,
      "step": 2800
    },
    {
      "epoch": 1.8789976920540719,
      "grad_norm": 5.995234966278076,
      "learning_rate": 8.794871794871795e-07,
      "loss": 0.199,
      "step": 2850
    },
    {
      "epoch": 1.9119683481701286,
      "grad_norm": 5.251335144042969,
      "learning_rate": 8.769230769230769e-07,
      "loss": 0.182,
      "step": 2900
    },
    {
      "epoch": 1.9449390042861854,
      "grad_norm": 3.7973928451538086,
      "learning_rate": 8.743589743589743e-07,
      "loss": 0.2018,
      "step": 2950
    },
    {
      "epoch": 1.9779096604022421,
      "grad_norm": 6.314321517944336,
      "learning_rate": 8.717948717948718e-07,
      "loss": 0.1946,
      "step": 3000
    },
    {
      "epoch": 1.9779096604022421,
      "eval_loss": 0.21684546768665314,
      "eval_runtime": 430.5752,
      "eval_samples_per_second": 14.086,
      "eval_steps_per_second": 1.763,
      "step": 3000
    },
    {
      "epoch": 2.010550609957138,
      "grad_norm": 6.713031768798828,
      "learning_rate": 8.692307692307692e-07,
      "loss": 0.1856,
      "step": 3050
    },
    {
      "epoch": 2.0435212660731947,
      "grad_norm": 6.765956878662109,
      "learning_rate": 8.666666666666667e-07,
      "loss": 0.1833,
      "step": 3100
    },
    {
      "epoch": 2.0764919221892515,
      "grad_norm": 7.709702491760254,
      "learning_rate": 8.641025641025641e-07,
      "loss": 0.1812,
      "step": 3150
    },
    {
      "epoch": 2.1094625783053083,
      "grad_norm": 6.051727294921875,
      "learning_rate": 8.615384615384616e-07,
      "loss": 0.1669,
      "step": 3200
    },
    {
      "epoch": 2.142433234421365,
      "grad_norm": 6.458124160766602,
      "learning_rate": 8.589743589743588e-07,
      "loss": 0.168,
      "step": 3250
    },
    {
      "epoch": 2.175403890537422,
      "grad_norm": 5.977611541748047,
      "learning_rate": 8.564102564102563e-07,
      "loss": 0.1846,
      "step": 3300
    },
    {
      "epoch": 2.2083745466534785,
      "grad_norm": 5.860900402069092,
      "learning_rate": 8.538461538461537e-07,
      "loss": 0.172,
      "step": 3350
    },
    {
      "epoch": 2.2413452027695353,
      "grad_norm": 5.188445091247559,
      "learning_rate": 8.512820512820512e-07,
      "loss": 0.1743,
      "step": 3400
    },
    {
      "epoch": 2.2743158588855916,
      "grad_norm": 7.304563522338867,
      "learning_rate": 8.487179487179486e-07,
      "loss": 0.1746,
      "step": 3450
    },
    {
      "epoch": 2.3072865150016484,
      "grad_norm": 6.339078903198242,
      "learning_rate": 8.461538461538461e-07,
      "loss": 0.1558,
      "step": 3500
    },
    {
      "epoch": 2.3072865150016484,
      "eval_loss": 0.21204371750354767,
      "eval_runtime": 434.4962,
      "eval_samples_per_second": 13.959,
      "eval_steps_per_second": 1.747,
      "step": 3500
    },
    {
      "epoch": 2.340257171117705,
      "grad_norm": 7.349090099334717,
      "learning_rate": 8.435897435897435e-07,
      "loss": 0.1753,
      "step": 3550
    },
    {
      "epoch": 2.373227827233762,
      "grad_norm": 6.100744247436523,
      "learning_rate": 8.41025641025641e-07,
      "loss": 0.1715,
      "step": 3600
    },
    {
      "epoch": 2.4061984833498187,
      "grad_norm": 4.850130558013916,
      "learning_rate": 8.384615384615384e-07,
      "loss": 0.1613,
      "step": 3650
    },
    {
      "epoch": 2.4391691394658754,
      "grad_norm": 5.98478364944458,
      "learning_rate": 8.358974358974359e-07,
      "loss": 0.171,
      "step": 3700
    },
    {
      "epoch": 2.472139795581932,
      "grad_norm": 6.22468900680542,
      "learning_rate": 8.333333333333333e-07,
      "loss": 0.1638,
      "step": 3750
    },
    {
      "epoch": 2.5051104516979885,
      "grad_norm": 4.591294765472412,
      "learning_rate": 8.307692307692308e-07,
      "loss": 0.1676,
      "step": 3800
    },
    {
      "epoch": 2.5380811078140457,
      "grad_norm": 6.629517078399658,
      "learning_rate": 8.282051282051282e-07,
      "loss": 0.167,
      "step": 3850
    },
    {
      "epoch": 2.571051763930102,
      "grad_norm": 6.902240753173828,
      "learning_rate": 8.256410256410256e-07,
      "loss": 0.1696,
      "step": 3900
    },
    {
      "epoch": 2.604022420046159,
      "grad_norm": 5.802059650421143,
      "learning_rate": 8.23076923076923e-07,
      "loss": 0.1696,
      "step": 3950
    },
    {
      "epoch": 2.6369930761622156,
      "grad_norm": 5.0160441398620605,
      "learning_rate": 8.205128205128205e-07,
      "loss": 0.1523,
      "step": 4000
    },
    {
      "epoch": 2.6369930761622156,
      "eval_loss": 0.20781303942203522,
      "eval_runtime": 438.5654,
      "eval_samples_per_second": 13.829,
      "eval_steps_per_second": 1.731,
      "step": 4000
    },
    {
      "epoch": 2.6699637322782723,
      "grad_norm": 5.1561431884765625,
      "learning_rate": 8.179487179487179e-07,
      "loss": 0.1594,
      "step": 4050
    },
    {
      "epoch": 2.702934388394329,
      "grad_norm": 5.068023204803467,
      "learning_rate": 8.153846153846154e-07,
      "loss": 0.1473,
      "step": 4100
    },
    {
      "epoch": 2.735905044510386,
      "grad_norm": 5.152896404266357,
      "learning_rate": 8.128205128205128e-07,
      "loss": 0.155,
      "step": 4150
    },
    {
      "epoch": 2.7688757006264426,
      "grad_norm": 4.919102668762207,
      "learning_rate": 8.102564102564103e-07,
      "loss": 0.1787,
      "step": 4200
    },
    {
      "epoch": 2.801846356742499,
      "grad_norm": 8.971311569213867,
      "learning_rate": 8.076923076923077e-07,
      "loss": 0.1528,
      "step": 4250
    },
    {
      "epoch": 2.834817012858556,
      "grad_norm": 6.975865364074707,
      "learning_rate": 8.051282051282052e-07,
      "loss": 0.1533,
      "step": 4300
    },
    {
      "epoch": 2.8677876689746125,
      "grad_norm": 7.575870037078857,
      "learning_rate": 8.025641025641025e-07,
      "loss": 0.1595,
      "step": 4350
    },
    {
      "epoch": 2.900758325090669,
      "grad_norm": 7.541371822357178,
      "learning_rate": 8e-07,
      "loss": 0.1665,
      "step": 4400
    },
    {
      "epoch": 2.933728981206726,
      "grad_norm": 6.23036003112793,
      "learning_rate": 7.974358974358974e-07,
      "loss": 0.1526,
      "step": 4450
    },
    {
      "epoch": 2.9666996373227827,
      "grad_norm": 6.061228275299072,
      "learning_rate": 7.948717948717948e-07,
      "loss": 0.1704,
      "step": 4500
    },
    {
      "epoch": 2.9666996373227827,
      "eval_loss": 0.2035084217786789,
      "eval_runtime": 446.3743,
      "eval_samples_per_second": 13.587,
      "eval_steps_per_second": 1.7,
      "step": 4500
    },
    {
      "epoch": 2.9996702934388395,
      "grad_norm": 6.7574663162231445,
      "learning_rate": 7.923076923076922e-07,
      "loss": 0.1575,
      "step": 4550
    },
    {
      "epoch": 3.032311242993736,
      "grad_norm": 4.30993127822876,
      "learning_rate": 7.897435897435897e-07,
      "loss": 0.1313,
      "step": 4600
    },
    {
      "epoch": 3.065281899109792,
      "grad_norm": 6.333834648132324,
      "learning_rate": 7.871794871794871e-07,
      "loss": 0.1413,
      "step": 4650
    },
    {
      "epoch": 3.098252555225849,
      "grad_norm": 4.843896865844727,
      "learning_rate": 7.846153846153846e-07,
      "loss": 0.1488,
      "step": 4700
    },
    {
      "epoch": 3.1312232113419056,
      "grad_norm": 4.6450276374816895,
      "learning_rate": 7.82051282051282e-07,
      "loss": 0.133,
      "step": 4750
    },
    {
      "epoch": 3.1641938674579624,
      "grad_norm": 4.9964518547058105,
      "learning_rate": 7.794871794871795e-07,
      "loss": 0.1395,
      "step": 4800
    },
    {
      "epoch": 3.197164523574019,
      "grad_norm": 4.861659049987793,
      "learning_rate": 7.769230769230769e-07,
      "loss": 0.1371,
      "step": 4850
    },
    {
      "epoch": 3.230135179690076,
      "grad_norm": 5.0479960441589355,
      "learning_rate": 7.743589743589744e-07,
      "loss": 0.1542,
      "step": 4900
    },
    {
      "epoch": 3.2631058358061327,
      "grad_norm": 6.771552085876465,
      "learning_rate": 7.717948717948718e-07,
      "loss": 0.1403,
      "step": 4950
    },
    {
      "epoch": 3.2960764919221894,
      "grad_norm": 5.19620943069458,
      "learning_rate": 7.692307692307693e-07,
      "loss": 0.1444,
      "step": 5000
    },
    {
      "epoch": 3.2960764919221894,
      "eval_loss": 0.200881689786911,
      "eval_runtime": 443.1341,
      "eval_samples_per_second": 13.687,
      "eval_steps_per_second": 1.713,
      "step": 5000
    },
    {
      "epoch": 3.3290471480382458,
      "grad_norm": 5.135739803314209,
      "learning_rate": 7.666666666666667e-07,
      "loss": 0.1318,
      "step": 5050
    },
    {
      "epoch": 3.3620178041543025,
      "grad_norm": 4.972677707672119,
      "learning_rate": 7.64102564102564e-07,
      "loss": 0.1263,
      "step": 5100
    },
    {
      "epoch": 3.3949884602703593,
      "grad_norm": 5.960831165313721,
      "learning_rate": 7.615384615384615e-07,
      "loss": 0.1388,
      "step": 5150
    },
    {
      "epoch": 3.427959116386416,
      "grad_norm": 5.012185096740723,
      "learning_rate": 7.589743589743589e-07,
      "loss": 0.1296,
      "step": 5200
    },
    {
      "epoch": 3.460929772502473,
      "grad_norm": 4.764325141906738,
      "learning_rate": 7.564102564102564e-07,
      "loss": 0.1322,
      "step": 5250
    },
    {
      "epoch": 3.4939004286185296,
      "grad_norm": 5.483187675476074,
      "learning_rate": 7.538461538461538e-07,
      "loss": 0.1352,
      "step": 5300
    },
    {
      "epoch": 3.5268710847345863,
      "grad_norm": 6.906312942504883,
      "learning_rate": 7.512820512820513e-07,
      "loss": 0.1292,
      "step": 5350
    },
    {
      "epoch": 3.559841740850643,
      "grad_norm": 5.929259777069092,
      "learning_rate": 7.487179487179486e-07,
      "loss": 0.1372,
      "step": 5400
    },
    {
      "epoch": 3.5928123969667,
      "grad_norm": 5.436402797698975,
      "learning_rate": 7.461538461538461e-07,
      "loss": 0.1294,
      "step": 5450
    },
    {
      "epoch": 3.625783053082756,
      "grad_norm": 4.503233909606934,
      "learning_rate": 7.435897435897435e-07,
      "loss": 0.1518,
      "step": 5500
    },
    {
      "epoch": 3.625783053082756,
      "eval_loss": 0.1983717828989029,
      "eval_runtime": 443.0986,
      "eval_samples_per_second": 13.688,
      "eval_steps_per_second": 1.713,
      "step": 5500
    },
    {
      "epoch": 3.658753709198813,
      "grad_norm": 6.26162052154541,
      "learning_rate": 7.41025641025641e-07,
      "loss": 0.1433,
      "step": 5550
    },
    {
      "epoch": 3.6917243653148697,
      "grad_norm": 4.493345737457275,
      "learning_rate": 7.384615384615384e-07,
      "loss": 0.1385,
      "step": 5600
    },
    {
      "epoch": 3.7246950214309265,
      "grad_norm": 5.879249572753906,
      "learning_rate": 7.358974358974359e-07,
      "loss": 0.1535,
      "step": 5650
    },
    {
      "epoch": 3.757665677546983,
      "grad_norm": 5.085137844085693,
      "learning_rate": 7.333333333333332e-07,
      "loss": 0.1479,
      "step": 5700
    },
    {
      "epoch": 3.79063633366304,
      "grad_norm": 5.211981296539307,
      "learning_rate": 7.307692307692307e-07,
      "loss": 0.1312,
      "step": 5750
    },
    {
      "epoch": 3.8236069897790967,
      "grad_norm": 6.3866729736328125,
      "learning_rate": 7.282051282051281e-07,
      "loss": 0.1383,
      "step": 5800
    },
    {
      "epoch": 3.856577645895153,
      "grad_norm": 4.576108455657959,
      "learning_rate": 7.256410256410256e-07,
      "loss": 0.1432,
      "step": 5850
    },
    {
      "epoch": 3.8895483020112103,
      "grad_norm": 5.557605743408203,
      "learning_rate": 7.23076923076923e-07,
      "loss": 0.1246,
      "step": 5900
    },
    {
      "epoch": 3.9225189581272666,
      "grad_norm": 6.118072986602783,
      "learning_rate": 7.205128205128205e-07,
      "loss": 0.1412,
      "step": 5950
    },
    {
      "epoch": 3.9554896142433233,
      "grad_norm": 4.801357269287109,
      "learning_rate": 7.179487179487179e-07,
      "loss": 0.1392,
      "step": 6000
    },
    {
      "epoch": 3.9554896142433233,
      "eval_loss": 0.19510263204574585,
      "eval_runtime": 447.2384,
      "eval_samples_per_second": 13.561,
      "eval_steps_per_second": 1.697,
      "step": 6000
    },
    {
      "epoch": 3.98846027035938,
      "grad_norm": 5.5764384269714355,
      "learning_rate": 7.153846153846154e-07,
      "loss": 0.1311,
      "step": 6050
    },
    {
      "epoch": 4.021101219914276,
      "grad_norm": 7.166302680969238,
      "learning_rate": 7.128205128205128e-07,
      "loss": 0.1245,
      "step": 6100
    },
    {
      "epoch": 4.054071876030333,
      "grad_norm": 3.708376884460449,
      "learning_rate": 7.102564102564103e-07,
      "loss": 0.1305,
      "step": 6150
    },
    {
      "epoch": 4.0870425321463895,
      "grad_norm": 4.524444580078125,
      "learning_rate": 7.076923076923077e-07,
      "loss": 0.1092,
      "step": 6200
    },
    {
      "epoch": 4.120013188262447,
      "grad_norm": 4.830074310302734,
      "learning_rate": 7.051282051282052e-07,
      "loss": 0.1042,
      "step": 6250
    },
    {
      "epoch": 4.152983844378503,
      "grad_norm": 6.2139434814453125,
      "learning_rate": 7.025641025641025e-07,
      "loss": 0.1116,
      "step": 6300
    },
    {
      "epoch": 4.18595450049456,
      "grad_norm": 4.130706787109375,
      "learning_rate": 7e-07,
      "loss": 0.1161,
      "step": 6350
    },
    {
      "epoch": 4.2189251566106165,
      "grad_norm": 5.6594390869140625,
      "learning_rate": 6.974358974358974e-07,
      "loss": 0.1154,
      "step": 6400
    },
    {
      "epoch": 4.251895812726673,
      "grad_norm": 5.041440010070801,
      "learning_rate": 6.948717948717948e-07,
      "loss": 0.1219,
      "step": 6450
    },
    {
      "epoch": 4.28486646884273,
      "grad_norm": 5.684177875518799,
      "learning_rate": 6.923076923076922e-07,
      "loss": 0.1233,
      "step": 6500
    },
    {
      "epoch": 4.28486646884273,
      "eval_loss": 0.19463331997394562,
      "eval_runtime": 452.6136,
      "eval_samples_per_second": 13.4,
      "eval_steps_per_second": 1.677,
      "step": 6500
    },
    {
      "epoch": 4.317837124958786,
      "grad_norm": 4.063368797302246,
      "learning_rate": 6.897435897435897e-07,
      "loss": 0.1244,
      "step": 6550
    },
    {
      "epoch": 4.350807781074844,
      "grad_norm": 6.785504341125488,
      "learning_rate": 6.871794871794871e-07,
      "loss": 0.1192,
      "step": 6600
    },
    {
      "epoch": 4.3837784371909,
      "grad_norm": 5.930688858032227,
      "learning_rate": 6.846153846153846e-07,
      "loss": 0.1184,
      "step": 6650
    },
    {
      "epoch": 4.416749093306957,
      "grad_norm": 5.32542610168457,
      "learning_rate": 6.82051282051282e-07,
      "loss": 0.1103,
      "step": 6700
    },
    {
      "epoch": 4.449719749423013,
      "grad_norm": 4.44658088684082,
      "learning_rate": 6.794871794871795e-07,
      "loss": 0.1206,
      "step": 6750
    },
    {
      "epoch": 4.482690405539071,
      "grad_norm": 4.829832077026367,
      "learning_rate": 6.769230769230769e-07,
      "loss": 0.121,
      "step": 6800
    },
    {
      "epoch": 4.515661061655127,
      "grad_norm": 5.672304630279541,
      "learning_rate": 6.743589743589744e-07,
      "loss": 0.1176,
      "step": 6850
    },
    {
      "epoch": 4.548631717771183,
      "grad_norm": 7.132081031799316,
      "learning_rate": 6.717948717948717e-07,
      "loss": 0.1234,
      "step": 6900
    },
    {
      "epoch": 4.5816023738872405,
      "grad_norm": 6.48559045791626,
      "learning_rate": 6.692307692307692e-07,
      "loss": 0.112,
      "step": 6950
    },
    {
      "epoch": 4.614573030003297,
      "grad_norm": 5.252386093139648,
      "learning_rate": 6.666666666666666e-07,
      "loss": 0.1112,
      "step": 7000
    },
    {
      "epoch": 4.614573030003297,
      "eval_loss": 0.19306428730487823,
      "eval_runtime": 459.1677,
      "eval_samples_per_second": 13.209,
      "eval_steps_per_second": 1.653,
      "step": 7000
    },
    {
      "epoch": 4.647543686119354,
      "grad_norm": 4.730811595916748,
      "learning_rate": 6.64102564102564e-07,
      "loss": 0.1119,
      "step": 7050
    },
    {
      "epoch": 4.68051434223541,
      "grad_norm": 6.1891703605651855,
      "learning_rate": 6.615384615384615e-07,
      "loss": 0.115,
      "step": 7100
    },
    {
      "epoch": 4.7134849983514675,
      "grad_norm": 5.228087425231934,
      "learning_rate": 6.58974358974359e-07,
      "loss": 0.1177,
      "step": 7150
    },
    {
      "epoch": 4.746455654467524,
      "grad_norm": 5.141632080078125,
      "learning_rate": 6.564102564102564e-07,
      "loss": 0.1149,
      "step": 7200
    },
    {
      "epoch": 4.779426310583581,
      "grad_norm": 4.678454875946045,
      "learning_rate": 6.538461538461538e-07,
      "loss": 0.1029,
      "step": 7250
    },
    {
      "epoch": 4.812396966699637,
      "grad_norm": 4.1828742027282715,
      "learning_rate": 6.512820512820513e-07,
      "loss": 0.1106,
      "step": 7300
    },
    {
      "epoch": 4.845367622815694,
      "grad_norm": 5.867072582244873,
      "learning_rate": 6.487179487179487e-07,
      "loss": 0.117,
      "step": 7350
    },
    {
      "epoch": 4.878338278931751,
      "grad_norm": 4.3607306480407715,
      "learning_rate": 6.461538461538462e-07,
      "loss": 0.1207,
      "step": 7400
    },
    {
      "epoch": 4.911308935047807,
      "grad_norm": 3.3651058673858643,
      "learning_rate": 6.435897435897436e-07,
      "loss": 0.1202,
      "step": 7450
    },
    {
      "epoch": 4.944279591163864,
      "grad_norm": 5.759963512420654,
      "learning_rate": 6.410256410256411e-07,
      "loss": 0.1151,
      "step": 7500
    },
    {
      "epoch": 4.944279591163864,
      "eval_loss": 0.19181858003139496,
      "eval_runtime": 452.4433,
      "eval_samples_per_second": 13.405,
      "eval_steps_per_second": 1.678,
      "step": 7500
    },
    {
      "epoch": 4.977250247279921,
      "grad_norm": 4.297214508056641,
      "learning_rate": 6.384615384615383e-07,
      "loss": 0.1255,
      "step": 7550
    },
    {
      "epoch": 5.009891196834817,
      "grad_norm": 5.768215656280518,
      "learning_rate": 6.358974358974358e-07,
      "loss": 0.1223,
      "step": 7600
    },
    {
      "epoch": 5.042861852950874,
      "grad_norm": 3.8306727409362793,
      "learning_rate": 6.333333333333332e-07,
      "loss": 0.1063,
      "step": 7650
    },
    {
      "epoch": 5.07583250906693,
      "grad_norm": 3.8245317935943604,
      "learning_rate": 6.307692307692307e-07,
      "loss": 0.1001,
      "step": 7700
    },
    {
      "epoch": 5.108803165182987,
      "grad_norm": 6.544422626495361,
      "learning_rate": 6.282051282051281e-07,
      "loss": 0.1018,
      "step": 7750
    },
    {
      "epoch": 5.141773821299044,
      "grad_norm": 3.9452006816864014,
      "learning_rate": 6.256410256410256e-07,
      "loss": 0.0861,
      "step": 7800
    },
    {
      "epoch": 5.174744477415101,
      "grad_norm": 4.429234981536865,
      "learning_rate": 6.23076923076923e-07,
      "loss": 0.1007,
      "step": 7850
    },
    {
      "epoch": 5.207715133531157,
      "grad_norm": 6.361189365386963,
      "learning_rate": 6.205128205128205e-07,
      "loss": 0.0978,
      "step": 7900
    },
    {
      "epoch": 5.240685789647214,
      "grad_norm": 4.10236930847168,
      "learning_rate": 6.179487179487179e-07,
      "loss": 0.1021,
      "step": 7950
    },
    {
      "epoch": 5.273656445763271,
      "grad_norm": 3.4095876216888428,
      "learning_rate": 6.153846153846154e-07,
      "loss": 0.093,
      "step": 8000
    },
    {
      "epoch": 5.273656445763271,
      "eval_loss": 0.191452294588089,
      "eval_runtime": 453.7929,
      "eval_samples_per_second": 13.365,
      "eval_steps_per_second": 1.673,
      "step": 8000
    },
    {
      "epoch": 5.306627101879327,
      "grad_norm": 4.709709167480469,
      "learning_rate": 6.128205128205128e-07,
      "loss": 0.0998,
      "step": 8050
    },
    {
      "epoch": 5.339597757995384,
      "grad_norm": 6.127927303314209,
      "learning_rate": 6.102564102564103e-07,
      "loss": 0.0967,
      "step": 8100
    },
    {
      "epoch": 5.3725684141114405,
      "grad_norm": 3.864752769470215,
      "learning_rate": 6.076923076923076e-07,
      "loss": 0.1033,
      "step": 8150
    },
    {
      "epoch": 5.405539070227498,
      "grad_norm": 4.87045955657959,
      "learning_rate": 6.051282051282051e-07,
      "loss": 0.1028,
      "step": 8200
    },
    {
      "epoch": 5.438509726343554,
      "grad_norm": 2.209583282470703,
      "learning_rate": 6.025641025641025e-07,
      "loss": 0.0984,
      "step": 8250
    },
    {
      "epoch": 5.471480382459611,
      "grad_norm": 4.585720062255859,
      "learning_rate": 6e-07,
      "loss": 0.0997,
      "step": 8300
    },
    {
      "epoch": 5.5044510385756675,
      "grad_norm": 4.75465726852417,
      "learning_rate": 5.974358974358974e-07,
      "loss": 0.1012,
      "step": 8350
    },
    {
      "epoch": 5.537421694691725,
      "grad_norm": 3.774275302886963,
      "learning_rate": 5.948717948717949e-07,
      "loss": 0.0978,
      "step": 8400
    },
    {
      "epoch": 5.570392350807781,
      "grad_norm": 5.181327819824219,
      "learning_rate": 5.923076923076923e-07,
      "loss": 0.0995,
      "step": 8450
    },
    {
      "epoch": 5.603363006923837,
      "grad_norm": 5.606074333190918,
      "learning_rate": 5.897435897435898e-07,
      "loss": 0.1073,
      "step": 8500
    },
    {
      "epoch": 5.603363006923837,
      "eval_loss": 0.19005821645259857,
      "eval_runtime": 452.1683,
      "eval_samples_per_second": 13.413,
      "eval_steps_per_second": 1.679,
      "step": 8500
    },
    {
      "epoch": 5.636333663039895,
      "grad_norm": 3.9736430644989014,
      "learning_rate": 5.871794871794872e-07,
      "loss": 0.0965,
      "step": 8550
    },
    {
      "epoch": 5.669304319155951,
      "grad_norm": 3.885072946548462,
      "learning_rate": 5.846153846153847e-07,
      "loss": 0.1054,
      "step": 8600
    },
    {
      "epoch": 5.702274975272008,
      "grad_norm": 5.701706886291504,
      "learning_rate": 5.82051282051282e-07,
      "loss": 0.0977,
      "step": 8650
    },
    {
      "epoch": 5.735245631388064,
      "grad_norm": 4.655886650085449,
      "learning_rate": 5.794871794871795e-07,
      "loss": 0.0902,
      "step": 8700
    },
    {
      "epoch": 5.768216287504122,
      "grad_norm": 7.256398677825928,
      "learning_rate": 5.769230769230768e-07,
      "loss": 0.1065,
      "step": 8750
    },
    {
      "epoch": 5.801186943620178,
      "grad_norm": 4.529852390289307,
      "learning_rate": 5.743589743589743e-07,
      "loss": 0.1019,
      "step": 8800
    },
    {
      "epoch": 5.834157599736235,
      "grad_norm": 6.106818675994873,
      "learning_rate": 5.717948717948717e-07,
      "loss": 0.1022,
      "step": 8850
    },
    {
      "epoch": 5.8671282558522915,
      "grad_norm": 3.7338149547576904,
      "learning_rate": 5.692307692307692e-07,
      "loss": 0.0959,
      "step": 8900
    },
    {
      "epoch": 5.900098911968348,
      "grad_norm": 4.972990036010742,
      "learning_rate": 5.666666666666666e-07,
      "loss": 0.1101,
      "step": 8950
    },
    {
      "epoch": 5.933069568084405,
      "grad_norm": 4.55340576171875,
      "learning_rate": 5.641025641025641e-07,
      "loss": 0.0976,
      "step": 9000
    },
    {
      "epoch": 5.933069568084405,
      "eval_loss": 0.18826311826705933,
      "eval_runtime": 446.8713,
      "eval_samples_per_second": 13.572,
      "eval_steps_per_second": 1.698,
      "step": 9000
    },
    {
      "epoch": 5.966040224200461,
      "grad_norm": 5.720311164855957,
      "learning_rate": 5.615384615384615e-07,
      "loss": 0.1039,
      "step": 9050
    },
    {
      "epoch": 5.9990108803165185,
      "grad_norm": 4.0418195724487305,
      "learning_rate": 5.58974358974359e-07,
      "loss": 0.1003,
      "step": 9100
    },
    {
      "epoch": 6.031651829871414,
      "grad_norm": 4.465301036834717,
      "learning_rate": 5.564102564102564e-07,
      "loss": 0.0849,
      "step": 9150
    },
    {
      "epoch": 6.064622485987472,
      "grad_norm": 4.0557146072387695,
      "learning_rate": 5.538461538461539e-07,
      "loss": 0.0918,
      "step": 9200
    },
    {
      "epoch": 6.097593142103528,
      "grad_norm": 5.768016815185547,
      "learning_rate": 5.512820512820513e-07,
      "loss": 0.0835,
      "step": 9250
    },
    {
      "epoch": 6.130563798219584,
      "grad_norm": 2.2504100799560547,
      "learning_rate": 5.487179487179488e-07,
      "loss": 0.0833,
      "step": 9300
    },
    {
      "epoch": 6.163534454335641,
      "grad_norm": 5.512030601501465,
      "learning_rate": 5.461538461538461e-07,
      "loss": 0.0875,
      "step": 9350
    },
    {
      "epoch": 6.196505110451698,
      "grad_norm": 4.514389991760254,
      "learning_rate": 5.435897435897435e-07,
      "loss": 0.0829,
      "step": 9400
    },
    {
      "epoch": 6.229475766567755,
      "grad_norm": 4.959427356719971,
      "learning_rate": 5.41025641025641e-07,
      "loss": 0.0914,
      "step": 9450
    },
    {
      "epoch": 6.262446422683811,
      "grad_norm": 4.097788333892822,
      "learning_rate": 5.384615384615384e-07,
      "loss": 0.0928,
      "step": 9500
    },
    {
      "epoch": 6.262446422683811,
      "eval_loss": 0.18879301846027374,
      "eval_runtime": 442.538,
      "eval_samples_per_second": 13.705,
      "eval_steps_per_second": 1.715,
      "step": 9500
    },
    {
      "epoch": 6.2954170787998684,
      "grad_norm": 5.439979553222656,
      "learning_rate": 5.358974358974359e-07,
      "loss": 0.0904,
      "step": 9550
    },
    {
      "epoch": 6.328387734915925,
      "grad_norm": 4.525865077972412,
      "learning_rate": 5.333333333333333e-07,
      "loss": 0.0845,
      "step": 9600
    },
    {
      "epoch": 6.361358391031981,
      "grad_norm": 4.389438152313232,
      "learning_rate": 5.307692307692308e-07,
      "loss": 0.0874,
      "step": 9650
    },
    {
      "epoch": 6.394329047148038,
      "grad_norm": 4.606354713439941,
      "learning_rate": 5.282051282051282e-07,
      "loss": 0.0873,
      "step": 9700
    },
    {
      "epoch": 6.427299703264095,
      "grad_norm": 5.870671272277832,
      "learning_rate": 5.256410256410256e-07,
      "loss": 0.0877,
      "step": 9750
    },
    {
      "epoch": 6.460270359380152,
      "grad_norm": 5.9947052001953125,
      "learning_rate": 5.23076923076923e-07,
      "loss": 0.0843,
      "step": 9800
    },
    {
      "epoch": 6.493241015496208,
      "grad_norm": 2.864682197570801,
      "learning_rate": 5.205128205128205e-07,
      "loss": 0.0841,
      "step": 9850
    },
    {
      "epoch": 6.526211671612265,
      "grad_norm": 4.672658920288086,
      "learning_rate": 5.179487179487179e-07,
      "loss": 0.0798,
      "step": 9900
    },
    {
      "epoch": 6.559182327728322,
      "grad_norm": 3.330864906311035,
      "learning_rate": 5.153846153846153e-07,
      "loss": 0.0878,
      "step": 9950
    },
    {
      "epoch": 6.592152983844379,
      "grad_norm": 4.722942352294922,
      "learning_rate": 5.128205128205127e-07,
      "loss": 0.0891,
      "step": 10000
    },
    {
      "epoch": 6.592152983844379,
      "eval_loss": 0.18838569521903992,
      "eval_runtime": 439.8195,
      "eval_samples_per_second": 13.79,
      "eval_steps_per_second": 1.726,
      "step": 10000
    },
    {
      "epoch": 6.625123639960435,
      "grad_norm": 3.874518871307373,
      "learning_rate": 5.102564102564102e-07,
      "loss": 0.0878,
      "step": 10050
    },
    {
      "epoch": 6.6580942960764915,
      "grad_norm": 3.182288646697998,
      "learning_rate": 5.076923076923076e-07,
      "loss": 0.0944,
      "step": 10100
    },
    {
      "epoch": 6.691064952192549,
      "grad_norm": 3.265012502670288,
      "learning_rate": 5.051282051282051e-07,
      "loss": 0.0815,
      "step": 10150
    },
    {
      "epoch": 6.724035608308605,
      "grad_norm": 4.96837854385376,
      "learning_rate": 5.025641025641025e-07,
      "loss": 0.0765,
      "step": 10200
    },
    {
      "epoch": 6.757006264424662,
      "grad_norm": 4.725424766540527,
      "learning_rate": 5e-07,
      "loss": 0.0822,
      "step": 10250
    },
    {
      "epoch": 6.7899769205407186,
      "grad_norm": 5.434659004211426,
      "learning_rate": 4.974358974358974e-07,
      "loss": 0.0919,
      "step": 10300
    },
    {
      "epoch": 6.822947576656776,
      "grad_norm": 3.719921588897705,
      "learning_rate": 4.948717948717949e-07,
      "loss": 0.0924,
      "step": 10350
    },
    {
      "epoch": 6.855918232772832,
      "grad_norm": 4.419114589691162,
      "learning_rate": 4.923076923076923e-07,
      "loss": 0.0861,
      "step": 10400
    },
    {
      "epoch": 6.888888888888889,
      "grad_norm": 4.791433334350586,
      "learning_rate": 4.897435897435897e-07,
      "loss": 0.0898,
      "step": 10450
    },
    {
      "epoch": 6.921859545004946,
      "grad_norm": 4.339222431182861,
      "learning_rate": 4.871794871794871e-07,
      "loss": 0.096,
      "step": 10500
    },
    {
      "epoch": 6.921859545004946,
      "eval_loss": 0.18772433698177338,
      "eval_runtime": 432.8572,
      "eval_samples_per_second": 14.012,
      "eval_steps_per_second": 1.753,
      "step": 10500
    },
    {
      "epoch": 6.954830201121002,
      "grad_norm": 6.14692497253418,
      "learning_rate": 4.846153846153846e-07,
      "loss": 0.0891,
      "step": 10550
    },
    {
      "epoch": 6.987800857237059,
      "grad_norm": 4.760381698608398,
      "learning_rate": 4.82051282051282e-07,
      "loss": 0.0784,
      "step": 10600
    },
    {
      "epoch": 7.020441806791955,
      "grad_norm": 4.4037322998046875,
      "learning_rate": 4.794871794871795e-07,
      "loss": 0.0845,
      "step": 10650
    },
    {
      "epoch": 7.053412462908012,
      "grad_norm": 3.9491567611694336,
      "learning_rate": 4.769230769230769e-07,
      "loss": 0.0738,
      "step": 10700
    },
    {
      "epoch": 7.0863831190240685,
      "grad_norm": 3.494476556777954,
      "learning_rate": 4.743589743589743e-07,
      "loss": 0.0698,
      "step": 10750
    },
    {
      "epoch": 7.119353775140126,
      "grad_norm": 5.03651237487793,
      "learning_rate": 4.7179487179487176e-07,
      "loss": 0.0769,
      "step": 10800
    },
    {
      "epoch": 7.152324431256182,
      "grad_norm": 3.8372673988342285,
      "learning_rate": 4.692307692307692e-07,
      "loss": 0.0755,
      "step": 10850
    },
    {
      "epoch": 7.185295087372238,
      "grad_norm": 5.060736656188965,
      "learning_rate": 4.6666666666666666e-07,
      "loss": 0.0765,
      "step": 10900
    },
    {
      "epoch": 7.2182657434882955,
      "grad_norm": 5.671173572540283,
      "learning_rate": 4.641025641025641e-07,
      "loss": 0.0781,
      "step": 10950
    },
    {
      "epoch": 7.251236399604352,
      "grad_norm": 5.475936412811279,
      "learning_rate": 4.6153846153846156e-07,
      "loss": 0.0728,
      "step": 11000
    },
    {
      "epoch": 7.251236399604352,
      "eval_loss": 0.18808045983314514,
      "eval_runtime": 425.9677,
      "eval_samples_per_second": 14.238,
      "eval_steps_per_second": 1.782,
      "step": 11000
    },
    {
      "epoch": 7.284207055720409,
      "grad_norm": 3.739713191986084,
      "learning_rate": 4.5897435897435896e-07,
      "loss": 0.0768,
      "step": 11050
    },
    {
      "epoch": 7.317177711836465,
      "grad_norm": 4.354212760925293,
      "learning_rate": 4.5641025641025636e-07,
      "loss": 0.0787,
      "step": 11100
    },
    {
      "epoch": 7.350148367952523,
      "grad_norm": 2.514791250228882,
      "learning_rate": 4.538461538461538e-07,
      "loss": 0.072,
      "step": 11150
    },
    {
      "epoch": 7.383119024068579,
      "grad_norm": 4.034693241119385,
      "learning_rate": 4.5128205128205125e-07,
      "loss": 0.0745,
      "step": 11200
    },
    {
      "epoch": 7.416089680184635,
      "grad_norm": 5.181633472442627,
      "learning_rate": 4.487179487179487e-07,
      "loss": 0.0765,
      "step": 11250
    },
    {
      "epoch": 7.449060336300692,
      "grad_norm": 3.4877405166625977,
      "learning_rate": 4.4615384615384615e-07,
      "loss": 0.0701,
      "step": 11300
    },
    {
      "epoch": 7.482030992416749,
      "grad_norm": 5.5395426750183105,
      "learning_rate": 4.4358974358974355e-07,
      "loss": 0.0777,
      "step": 11350
    },
    {
      "epoch": 7.515001648532806,
      "grad_norm": 3.7528460025787354,
      "learning_rate": 4.41025641025641e-07,
      "loss": 0.0688,
      "step": 11400
    },
    {
      "epoch": 7.547972304648862,
      "grad_norm": 5.698997974395752,
      "learning_rate": 4.3846153846153845e-07,
      "loss": 0.0767,
      "step": 11450
    },
    {
      "epoch": 7.5809429607649195,
      "grad_norm": 4.0864787101745605,
      "learning_rate": 4.358974358974359e-07,
      "loss": 0.0698,
      "step": 11500
    },
    {
      "epoch": 7.5809429607649195,
      "eval_loss": 0.18812446296215057,
      "eval_runtime": 428.7161,
      "eval_samples_per_second": 14.147,
      "eval_steps_per_second": 1.77,
      "step": 11500
    },
    {
      "epoch": 7.613913616880976,
      "grad_norm": 3.3553826808929443,
      "learning_rate": 4.3333333333333335e-07,
      "loss": 0.0739,
      "step": 11550
    },
    {
      "epoch": 7.646884272997033,
      "grad_norm": 3.390331268310547,
      "learning_rate": 4.307692307692308e-07,
      "loss": 0.0871,
      "step": 11600
    },
    {
      "epoch": 7.679854929113089,
      "grad_norm": 2.3920669555664062,
      "learning_rate": 4.2820512820512814e-07,
      "loss": 0.079,
      "step": 11650
    },
    {
      "epoch": 7.712825585229146,
      "grad_norm": 3.8149449825286865,
      "learning_rate": 4.256410256410256e-07,
      "loss": 0.0839,
      "step": 11700
    },
    {
      "epoch": 7.745796241345203,
      "grad_norm": 5.113360404968262,
      "learning_rate": 4.2307692307692304e-07,
      "loss": 0.0733,
      "step": 11750
    },
    {
      "epoch": 7.778766897461259,
      "grad_norm": 5.099254608154297,
      "learning_rate": 4.205128205128205e-07,
      "loss": 0.0808,
      "step": 11800
    },
    {
      "epoch": 7.811737553577316,
      "grad_norm": 5.262718200683594,
      "learning_rate": 4.1794871794871794e-07,
      "loss": 0.0866,
      "step": 11850
    },
    {
      "epoch": 7.844708209693373,
      "grad_norm": 7.105816841125488,
      "learning_rate": 4.153846153846154e-07,
      "loss": 0.0723,
      "step": 11900
    },
    {
      "epoch": 7.87767886580943,
      "grad_norm": 3.126185417175293,
      "learning_rate": 4.128205128205128e-07,
      "loss": 0.0831,
      "step": 11950
    },
    {
      "epoch": 7.910649521925486,
      "grad_norm": 4.399303913116455,
      "learning_rate": 4.1025641025641024e-07,
      "loss": 0.0804,
      "step": 12000
    },
    {
      "epoch": 7.910649521925486,
      "eval_loss": 0.18710331618785858,
      "eval_runtime": 426.7814,
      "eval_samples_per_second": 14.211,
      "eval_steps_per_second": 1.778,
      "step": 12000
    },
    {
      "epoch": 7.943620178041543,
      "grad_norm": 5.995975494384766,
      "learning_rate": 4.076923076923077e-07,
      "loss": 0.0775,
      "step": 12050
    },
    {
      "epoch": 7.9765908341576,
      "grad_norm": 4.4365739822387695,
      "learning_rate": 4.0512820512820514e-07,
      "loss": 0.0679,
      "step": 12100
    },
    {
      "epoch": 8.009231783712496,
      "grad_norm": 3.8590433597564697,
      "learning_rate": 4.025641025641026e-07,
      "loss": 0.0748,
      "step": 12150
    },
    {
      "epoch": 8.042202439828552,
      "grad_norm": 5.119325160980225,
      "learning_rate": 4e-07,
      "loss": 0.0708,
      "step": 12200
    },
    {
      "epoch": 8.07517309594461,
      "grad_norm": 6.229057312011719,
      "learning_rate": 3.974358974358974e-07,
      "loss": 0.0777,
      "step": 12250
    },
    {
      "epoch": 8.108143752060666,
      "grad_norm": 4.661108016967773,
      "learning_rate": 3.9487179487179483e-07,
      "loss": 0.0704,
      "step": 12300
    },
    {
      "epoch": 8.141114408176723,
      "grad_norm": 4.1739583015441895,
      "learning_rate": 3.923076923076923e-07,
      "loss": 0.0664,
      "step": 12350
    },
    {
      "epoch": 8.174085064292779,
      "grad_norm": 4.92027473449707,
      "learning_rate": 3.8974358974358973e-07,
      "loss": 0.0741,
      "step": 12400
    },
    {
      "epoch": 8.207055720408835,
      "grad_norm": 4.142080307006836,
      "learning_rate": 3.871794871794872e-07,
      "loss": 0.0765,
      "step": 12450
    },
    {
      "epoch": 8.240026376524893,
      "grad_norm": 3.8432013988494873,
      "learning_rate": 3.8461538461538463e-07,
      "loss": 0.0678,
      "step": 12500
    },
    {
      "epoch": 8.240026376524893,
      "eval_loss": 0.18833069503307343,
      "eval_runtime": 428.8085,
      "eval_samples_per_second": 14.144,
      "eval_steps_per_second": 1.77,
      "step": 12500
    },
    {
      "epoch": 8.27299703264095,
      "grad_norm": 5.025969982147217,
      "learning_rate": 3.82051282051282e-07,
      "loss": 0.0627,
      "step": 12550
    },
    {
      "epoch": 8.305967688757006,
      "grad_norm": 3.968162775039673,
      "learning_rate": 3.7948717948717947e-07,
      "loss": 0.0667,
      "step": 12600
    },
    {
      "epoch": 8.338938344873062,
      "grad_norm": 4.249327659606934,
      "learning_rate": 3.769230769230769e-07,
      "loss": 0.0707,
      "step": 12650
    },
    {
      "epoch": 8.37190900098912,
      "grad_norm": 4.545931339263916,
      "learning_rate": 3.743589743589743e-07,
      "loss": 0.067,
      "step": 12700
    },
    {
      "epoch": 8.404879657105177,
      "grad_norm": 5.589274883270264,
      "learning_rate": 3.7179487179487177e-07,
      "loss": 0.0669,
      "step": 12750
    },
    {
      "epoch": 8.437850313221233,
      "grad_norm": 3.4576315879821777,
      "learning_rate": 3.692307692307692e-07,
      "loss": 0.0715,
      "step": 12800
    },
    {
      "epoch": 8.47082096933729,
      "grad_norm": 2.6135127544403076,
      "learning_rate": 3.666666666666666e-07,
      "loss": 0.066,
      "step": 12850
    },
    {
      "epoch": 8.503791625453346,
      "grad_norm": 4.4812774658203125,
      "learning_rate": 3.6410256410256406e-07,
      "loss": 0.0667,
      "step": 12900
    },
    {
      "epoch": 8.536762281569404,
      "grad_norm": 3.989935874938965,
      "learning_rate": 3.615384615384615e-07,
      "loss": 0.0641,
      "step": 12950
    },
    {
      "epoch": 8.56973293768546,
      "grad_norm": 2.407205104827881,
      "learning_rate": 3.5897435897435896e-07,
      "loss": 0.0683,
      "step": 13000
    },
    {
      "epoch": 8.56973293768546,
      "eval_loss": 0.18812260031700134,
      "eval_runtime": 435.6407,
      "eval_samples_per_second": 13.922,
      "eval_steps_per_second": 1.742,
      "step": 13000
    },
    {
      "epoch": 8.602703593801516,
      "grad_norm": 4.357760429382324,
      "learning_rate": 3.564102564102564e-07,
      "loss": 0.0611,
      "step": 13050
    },
    {
      "epoch": 8.635674249917573,
      "grad_norm": 4.8706183433532715,
      "learning_rate": 3.5384615384615386e-07,
      "loss": 0.0663,
      "step": 13100
    },
    {
      "epoch": 8.66864490603363,
      "grad_norm": 3.446977138519287,
      "learning_rate": 3.5128205128205126e-07,
      "loss": 0.0611,
      "step": 13150
    },
    {
      "epoch": 8.701615562149687,
      "grad_norm": 5.127050399780273,
      "learning_rate": 3.487179487179487e-07,
      "loss": 0.0624,
      "step": 13200
    },
    {
      "epoch": 8.734586218265743,
      "grad_norm": 3.77138614654541,
      "learning_rate": 3.461538461538461e-07,
      "loss": 0.0666,
      "step": 13250
    },
    {
      "epoch": 8.7675568743818,
      "grad_norm": 2.7949635982513428,
      "learning_rate": 3.4358974358974356e-07,
      "loss": 0.0687,
      "step": 13300
    },
    {
      "epoch": 8.800527530497856,
      "grad_norm": 3.83719539642334,
      "learning_rate": 3.41025641025641e-07,
      "loss": 0.0716,
      "step": 13350
    },
    {
      "epoch": 8.833498186613914,
      "grad_norm": 3.1905972957611084,
      "learning_rate": 3.3846153846153845e-07,
      "loss": 0.0673,
      "step": 13400
    },
    {
      "epoch": 8.86646884272997,
      "grad_norm": 3.647062063217163,
      "learning_rate": 3.3589743589743585e-07,
      "loss": 0.0729,
      "step": 13450
    },
    {
      "epoch": 8.899439498846027,
      "grad_norm": 5.208111763000488,
      "learning_rate": 3.333333333333333e-07,
      "loss": 0.0647,
      "step": 13500
    },
    {
      "epoch": 8.899439498846027,
      "eval_loss": 0.18775086104869843,
      "eval_runtime": 433.5363,
      "eval_samples_per_second": 13.99,
      "eval_steps_per_second": 1.751,
      "step": 13500
    },
    {
      "epoch": 8.932410154962083,
      "grad_norm": 5.284823417663574,
      "learning_rate": 3.3076923076923075e-07,
      "loss": 0.0663,
      "step": 13550
    },
    {
      "epoch": 8.965380811078141,
      "grad_norm": 5.737663745880127,
      "learning_rate": 3.282051282051282e-07,
      "loss": 0.07,
      "step": 13600
    },
    {
      "epoch": 8.998351467194198,
      "grad_norm": 4.0488739013671875,
      "learning_rate": 3.2564102564102565e-07,
      "loss": 0.0646,
      "step": 13650
    },
    {
      "epoch": 9.030992416749093,
      "grad_norm": 2.8303253650665283,
      "learning_rate": 3.230769230769231e-07,
      "loss": 0.0609,
      "step": 13700
    },
    {
      "epoch": 9.06396307286515,
      "grad_norm": 2.7293670177459717,
      "learning_rate": 3.2051282051282055e-07,
      "loss": 0.0582,
      "step": 13750
    },
    {
      "epoch": 9.096933728981206,
      "grad_norm": 3.274568557739258,
      "learning_rate": 3.179487179487179e-07,
      "loss": 0.0636,
      "step": 13800
    },
    {
      "epoch": 9.129904385097264,
      "grad_norm": 4.617187976837158,
      "learning_rate": 3.1538461538461534e-07,
      "loss": 0.056,
      "step": 13850
    },
    {
      "epoch": 9.16287504121332,
      "grad_norm": 5.4811577796936035,
      "learning_rate": 3.128205128205128e-07,
      "loss": 0.0637,
      "step": 13900
    },
    {
      "epoch": 9.195845697329377,
      "grad_norm": 5.083188056945801,
      "learning_rate": 3.1025641025641024e-07,
      "loss": 0.0616,
      "step": 13950
    },
    {
      "epoch": 9.228816353445433,
      "grad_norm": 4.885318279266357,
      "learning_rate": 3.076923076923077e-07,
      "loss": 0.0614,
      "step": 14000
    },
    {
      "epoch": 9.228816353445433,
      "eval_loss": 0.18812265992164612,
      "eval_runtime": 432.8247,
      "eval_samples_per_second": 14.013,
      "eval_steps_per_second": 1.754,
      "step": 14000
    },
    {
      "epoch": 9.261787009561491,
      "grad_norm": 4.463879585266113,
      "learning_rate": 3.0512820512820514e-07,
      "loss": 0.0575,
      "step": 14050
    },
    {
      "epoch": 9.294757665677547,
      "grad_norm": 3.9244725704193115,
      "learning_rate": 3.0256410256410254e-07,
      "loss": 0.0612,
      "step": 14100
    },
    {
      "epoch": 9.327728321793604,
      "grad_norm": 6.3790106773376465,
      "learning_rate": 3e-07,
      "loss": 0.0649,
      "step": 14150
    },
    {
      "epoch": 9.36069897790966,
      "grad_norm": 2.9226889610290527,
      "learning_rate": 2.9743589743589744e-07,
      "loss": 0.0622,
      "step": 14200
    },
    {
      "epoch": 9.393669634025716,
      "grad_norm": 3.283351182937622,
      "learning_rate": 2.948717948717949e-07,
      "loss": 0.0638,
      "step": 14250
    },
    {
      "epoch": 9.426640290141775,
      "grad_norm": 4.327844619750977,
      "learning_rate": 2.9230769230769234e-07,
      "loss": 0.0573,
      "step": 14300
    },
    {
      "epoch": 9.45961094625783,
      "grad_norm": 3.136836051940918,
      "learning_rate": 2.8974358974358973e-07,
      "loss": 0.0622,
      "step": 14350
    },
    {
      "epoch": 9.492581602373887,
      "grad_norm": 4.764090061187744,
      "learning_rate": 2.8717948717948713e-07,
      "loss": 0.0665,
      "step": 14400
    },
    {
      "epoch": 9.525552258489943,
      "grad_norm": 4.878819465637207,
      "learning_rate": 2.846153846153846e-07,
      "loss": 0.0635,
      "step": 14450
    },
    {
      "epoch": 9.558522914606002,
      "grad_norm": 4.16619873046875,
      "learning_rate": 2.8205128205128203e-07,
      "loss": 0.0618,
      "step": 14500
    },
    {
      "epoch": 9.558522914606002,
      "eval_loss": 0.18837828934192657,
      "eval_runtime": 435.0655,
      "eval_samples_per_second": 13.94,
      "eval_steps_per_second": 1.745,
      "step": 14500
    }
  ],
  "logging_steps": 50,
  "max_steps": 20000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 14,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 5,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 5
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.691804838240256e+19,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
