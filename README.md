# Whisper-small 파인튜닝 (노인 자연 발화 STT)

팀 프로젝트에서 사용할 STT 품질을 높이기 위해 **OpenAI Whisper-small**을 AI-Hub **노인 남여 자유대화 음성** 데이터셋으로 파인튜닝했습니다. 이 문서는 해당 프로젝트에서 사용하기 위해 거친 데이터 전처리 과정과 학습 설정, 핵심 성능 지표를 정리하기 위한 문서입니다.

## 왜 노인 발화 데이터셋인가?
* 노인의 경우 청년층과 사투리, 억양 등에서 다른 연령층과는 차별되는 발화 양상을 보이는 경향이 있습니다.
* 따라서 Whisper 모델의 경우에도 노인 발화를 잘 감지하지 못하고, 오탈자율이 상승하는 경향성이 있습니다.
* 저희 프로젝트에서는 모든 세대가 사용 가능한 '음성 채팅' 기능을 지원할 예정으로, 허깅 페이스에 공개되어있는 openai의 whisper-small 모델을 ai hub의 데이터셋으로 파인튜닝하여 이러한 오탈자를 개선하고 노인의 자연 발화를 더 잘 짚어낼 수 있도록 하였습니다.

---

## 데이터셋

* **소스**: AI-Hub *자유대화 음성(노인남여)*
* **전처리 개요**

  * 오디오: 16kHz mono 리샘플
  * 텍스트: 불필요 기호 제거, 공백/표기 정규화
  * 분할: 무작위로 train/validation/test 분리
  * 토크나이저: Whisper 기본 ko tokenizer


---

## 모델 & 학습 설정

* **베이스 모델**: `openai/whisper-small`
* **학습 전략**: step 기반 학습, `eval_steps=500`
* **Early Stop**: 사용(검증 **eval loss** 기준)
* **베스트 체크포인트**: `./whisper-train-1029/checkpoint-12000`

### 로그 요약

```txt
best_metric (eval loss): 0.18710331618785858
best_model_checkpoint: ./whisper-train-1029/checkpoint-12000
epoch: 9.558522914606002
eval_steps: 500
global_step: 14500
```

---

## 결과

| 지표      | 파인튜닝 전 | 파인튜닝 후 |        개선 폭 |
| ------- | -----: | -----: | ----------: |
| **CER** | 0.1157 | 0.0447 | **-0.0710** |

* **평가 기준**: 테스트 세트에서 Character Error Rate(CER) 측정
* **의미**: 노년층 자연 발화 특성(발화 속도, 억양, 발음 변이 등)에 대한 적응으로 오탈자율이 유의미하게 감소
* 추가적으로 내부 모니터링은 **eval loss** 기준으로 얼리 스토핑을 적용했습니다. (WER 등은 필요 시 별도 보고)

> 해석: CER 약 **0.116 → 0.045**로 하락. 실제 사용 환경에서 전사/자막 후처리 부담이 줄어드는 것을 확인.

---

* **체크포인트 선택**: `./whisper-train-1029/checkpoint-12000` (eval loss 기준 best)
* **인퍼런스**: best 체크포인트 로드 후 `generate()` 기반 디코딩(beam/temperature 등은 환경에 맞게 조정)

---

## 유의사항

* **도메인 특화**: 노인 자연 발화에 최적화되어 일반 도메인/잡음 환경에서의 성능은 별도 검증 필요
* **긴 발화 처리**: whisper 모델 입력 특성상 30초 이상 발화는 chunking 필요.

---

### TL;DR

* Whisper-small을 **노인 자연 발화**로 파인튜닝 → **CER 0.116 → 0.045** 개선
* step 기반 모니터링(`eval_steps=500`), 얼리 스토핑 적용
* best 체크포인트: `checkpoint-12000` (eval loss 기준)
